{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nicolasalan/td3/blob/main/vault.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUkL1MTSs3Nn"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s53BlzVCk8g_",
        "outputId": "5c739e97-3d48-4cb7-ca59-d01903e3f6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 28 17:12:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAddaBONmh68"
      },
      "source": [
        "Adicionar script ao console desse navegador: `inspecionar` => `console` => `adicionar script`.\n",
        "```\n",
        "function ConnectButton(){\n",
        "    console.log(\"Conectado\");\n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkNza9le_wuU"
      },
      "source": [
        "# **Install**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qa_nNJfpVwX"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install swig\n",
        "\n",
        "!pip install gymnasium\n",
        "!pip install gymnasium[box2d]\n",
        "\n",
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAatMkwQCxk5"
      },
      "source": [
        "# **TD3 - Twin Delayed DDPG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhKTN31AC0QQ"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from collections import namedtuple, deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH0qgyzCC1r7",
        "outputId": "8cec7110-7be8-4b08-8f5b-fd56b7459bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
        "BATCH_SIZE = 100        # minibatch size\n",
        "GAMMA = 0.99            # discount factor\n",
        "TAU = 1e-3              # for soft update of target parameters\n",
        "LR_ACTOR = 1e-3         # learning rate of the actor\n",
        "LR_CRITIC = 1e-3        # learning rate of the critic\n",
        "UPDATE_EVERY_STEP = 2   # how often to update the target and actor networks\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PIsAAovC3pL"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
        "\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)  # internal memory (deque)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7pJLds6C4gq"
      },
      "outputs": [],
      "source": [
        "def hidden_init(layer):\n",
        "    fan_in = layer.weight.data.size()[0]\n",
        "    lim = 1. / np.sqrt(fan_in)\n",
        "    return (-lim, lim)\n",
        "\n",
        "class Actor(nn.Module):\n",
        "\n",
        "    def __init__(self, state_size, action_size, max_action, seed, l1=400, l2=300):\n",
        "        super(Actor, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "\n",
        "        self.l1 = nn.Linear(state_size, l1)\n",
        "        self.l2 = nn.Linear(l1, l2)\n",
        "        self.l3 = nn.Linear(l2, action_size)\n",
        "        self.reset_parameters()\n",
        "\n",
        "        self.max_action = max_action\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.l1.weight.data.uniform_(*hidden_init(self.l1))\n",
        "        self.l2.weight.data.uniform_(*hidden_init(self.l2))\n",
        "        self.l3.weight.data.uniform_(-3e-3, 3e-3)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.l1(state))\n",
        "        x = F.relu(self.l2(x))\n",
        "        action = self.max_action * torch.tanh(self.l3(x))\n",
        "        return action\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, seed, l1=400, l2=300):\n",
        "        super(Critic, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "\n",
        "        self.l1 = nn.Linear(state_dim + action_dim, l1)\n",
        "        self.l2 = nn.Linear(l1, l2)\n",
        "        self.l3 = nn.Linear(action_dim, l2)\n",
        "        self.l4 = nn.Linear(l2, 1)\n",
        "        self.reset_parameters_q1()\n",
        "\n",
        "        self.l5 = nn.Linear(state_dim + action_dim, l1)\n",
        "        self.l6 = nn.Linear(l1, l2)\n",
        "        self.l7 = nn.Linear(action_dim, l2)\n",
        "        self.l8 = nn.Linear(l2, 1)\n",
        "        self.reset_parameters_q2()\n",
        "\n",
        "    def reset_parameters_q1(self):\n",
        "        self.l1.weight.data.uniform_(*hidden_init(self.l1))\n",
        "        self.l2.weight.data.uniform_(*hidden_init(self.l2))\n",
        "        self.l3.weight.data.uniform_(*hidden_init(self.l3))\n",
        "        self.l4.weight.data.uniform_(-3e-3, 3e-3)\n",
        "\n",
        "    def reset_parameters_q2(self):\n",
        "        self.l5.weight.data.uniform_(*hidden_init(self.l5))\n",
        "        self.l6.weight.data.uniform_(*hidden_init(self.l6))\n",
        "        self.l7.weight.data.uniform_(*hidden_init(self.l7))\n",
        "        self.l8.weight.data.uniform_(-3e-3, 3e-3)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "\n",
        "        s1 = F.relu(self.l1(torch.cat([state, action], dim=1)))\n",
        "        s1 = F.relu(self.l2(s1))\n",
        "        a1 = F.relu(self.l3(action))\n",
        "        s1 = s1 + a1\n",
        "        q1 = self.l4(s1)\n",
        "\n",
        "        s2 = F.relu(self.l5(torch.cat([state, action], dim=1)))\n",
        "        s2 = F.relu(self.l6(s2))\n",
        "        a2 = F.relu(self.l7(action))\n",
        "        s2 = s2 + a2\n",
        "        q2 = self.l8(s2)\n",
        "        return q1, q2\n",
        "\n",
        "    def Q1(self, state, action):\n",
        "        s1 = F.relu(self.l1(torch.cat([state, action], dim=1)))\n",
        "        s1 = F.relu(self.l2(s1))\n",
        "        a1 = F.relu(self.l3(action))\n",
        "        s1 = s1 + a1\n",
        "        q1 = self.l4(s1)\n",
        "        return q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3Cd3SiWC5Y5"
      },
      "outputs": [],
      "source": [
        "from numpy import inf\n",
        "\n",
        "class TD3Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, max_action, min_action, random_seed, noise=0.2, noise_std=0.1, noise_clip=0.5):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            action_size (int): dimension of each action\n",
        "            max_action (ndarray): the maximum valid value for each action vector\n",
        "            min_action (ndarray): the minimum valid value for each action vector\n",
        "            random_seed (int): random seed\n",
        "            noise (float): the range to generate random noise while learning\n",
        "            noise_std (float): the range to generate random noise while performing action\n",
        "            noise_clip (float): to clip random noise into this range\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.max_action = max_action\n",
        "        self.min_action = min_action\n",
        "        self.noise = noise\n",
        "        self.noise_std = noise_std\n",
        "        self.noise_clip = noise_clip\n",
        "\n",
        "        # Actor Network (w/ Target Network)\n",
        "        self.actor = Actor(state_size, action_size, float(max_action[0])).to(device)\n",
        "        self.actor_target = Actor(state_size, action_size, float(max_action[0])).to(device)\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=LR_ACTOR)\n",
        "\n",
        "        # Critic Network (w/ Target Network)\n",
        "        self.critic = Critic(state_size, action_size).to(device)\n",
        "        self.critic_target = Critic(state_size, action_size).to(device)\n",
        "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=LR_CRITIC)\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, random_seed)\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Save experience in replay memory\"\"\"\n",
        "\n",
        "        if isinstance(state, np.ndarray):\n",
        "            states = state\n",
        "        elif isinstance(state, tuple):\n",
        "            states = np.array(state[0], dtype=np.float32)\n",
        "\n",
        "        self.memory.add(states, action, reward, next_state, done)\n",
        "\n",
        "    def predict(self, states, add_noise=True):\n",
        "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
        "        if isinstance(states, np.ndarray):\n",
        "            convert_state = states\n",
        "        elif isinstance(states, tuple):\n",
        "            convert_state = np.array(states[0], dtype=np.float32)\n",
        "\n",
        "        state = torch.from_numpy(convert_state).float().to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            action = self.actor(state).cpu().data.numpy()\n",
        "\n",
        "        return action.clip(self.min_action[0], self.max_action[0])\n",
        "\n",
        "    def learn(self, n_iteraion, gamma=GAMMA):\n",
        "        \"\"\" Update policy and value parameters using given batch of experience tuples.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            n_iteraion (int): the number of iterations to train network\n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "\n",
        "        if len(self.memory) > BATCH_SIZE:\n",
        "            average_Q = 0\n",
        "            max_Q = -inf\n",
        "            average_loss = 0\n",
        "\n",
        "            for i in range(n_iteraion):\n",
        "                state, action, reward, next_state, done = self.memory.sample()\n",
        "\n",
        "                action_ = action.cpu().numpy()\n",
        "\n",
        "                # ---------------------------- update critic ---------------------------- #\n",
        "                # Get predicted next-state actions and Q values from target models\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    # Generate a random noise\n",
        "                    noise = torch.FloatTensor(action_).data.normal_(0, self.noise).to(device)\n",
        "                    noise = noise.clamp(-self.noise_clip, self.noise_clip)\n",
        "                    actions_next = (self.actor_target(next_state) + noise).clamp(self.min_action[0].astype(float), self.max_action[0].astype(float))\n",
        "\n",
        "                    Q1_targets_next, Q2_targets_next = self.critic_target(next_state, actions_next)\n",
        "\n",
        "                    Q_targets_next = torch.min(Q1_targets_next, Q2_targets_next)\n",
        "\n",
        "                    average_Q += torch.mean(Q_targets_next)\n",
        "                    max_Q = max(max_Q, torch.max(Q_targets_next))\n",
        "\n",
        "                    # Compute Q targets for current states (y_i)\n",
        "                    Q_targets = reward + (gamma * Q_targets_next * (1 - done)).detach()\n",
        "\n",
        "                # Compute critic loss\n",
        "                Q1_expected, Q2_expected = self.critic(state, action)\n",
        "                critic_loss = F.mse_loss(Q1_expected, Q_targets) + F.mse_loss(Q2_expected, Q_targets)\n",
        "\n",
        "                # Minimize the loss\n",
        "                self.critic_optimizer.zero_grad()\n",
        "                critic_loss.backward()\n",
        "                self.critic_optimizer.step()\n",
        "\n",
        "                if i % UPDATE_EVERY_STEP == 0:\n",
        "                    # ---------------------------- update actor ---------------------------- #\n",
        "                    # Compute actor loss\n",
        "                    actor_loss = -self.critic.Q1(state, self.actor(state)).mean()\n",
        "\n",
        "                    # Minimize the loss\n",
        "                    self.actor_optimizer.zero_grad()\n",
        "                    actor_loss.backward()\n",
        "                    self.actor_optimizer.step()\n",
        "\n",
        "                    # ----------------------- update target networks ----------------------- #\n",
        "                    self.soft_update(self.critic, self.critic_target, TAU)\n",
        "                    self.soft_update(self.actor, self.actor_target, TAU)\n",
        "\n",
        "                average_loss += critic_loss\n",
        "\n",
        "            loss = average_loss / n_iteraion\n",
        "            average_policy = average_Q / n_iteraion\n",
        "            max_policy = max_Q\n",
        "\n",
        "            return loss, average_policy, max_policy\n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "        Params\n",
        "        ======\n",
        "            local_model: PyTorch model (weights will be copied from)\n",
        "            target_model: PyTorch model (weights will be copied to)\n",
        "            tau (float): interpolation parameter\n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
        "\n",
        "    def save(self, filename):\n",
        "          \"\"\" Save the model \"\"\"\n",
        "          torch.save(self.critic.state_dict(), filename + \"_critic\")\n",
        "          torch.save(self.critic_optimizer.state_dict(), filename + \"_critic_optimizer\")\n",
        "\n",
        "          torch.save(self.actor.state_dict(), filename + \"_actor\")\n",
        "          torch.save(self.actor_optimizer.state_dict(), filename + \"_actor_optimizer\")\n",
        "\n",
        "    def load(self, filename):\n",
        "          \"\"\" Load the model \"\"\"\n",
        "          self.critic.load_state_dict(torch.load(filename + \"_critic\"))\n",
        "          self.critic_optimizer.load_state_dict(torch.load(filename + \"_critic_optimizer\"))\n",
        "          self.critic_target = copy.deepcopy(self.critic)\n",
        "\n",
        "          self.actor.load_state_dict(torch.load(filename + \"_actor\"))\n",
        "          self.actor_optimizer.load_state_dict(torch.load(filename + \"_actor_optimizer\"))\n",
        "          self.actor_target = copy.deepcopy(self.actor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9tSI3g3C9K0",
        "outputId": "f6882435-bbe0-479a-bdb2-59f217f876fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de cada ação: 4\n",
            "Ligação superior de cada ação: 1.0\n",
            "Ligação inferior de cada ação: -1.0\n",
            "Cada um observa um estado com comprimento: 24\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"BipedalWalker-v3\", hardcore=True)\n",
        "\n",
        "# tamanho de cada ação\n",
        "action_size = env.action_space\n",
        "print('Tamanho de cada ação:', action_size.shape[0])\n",
        "\n",
        "# vínculo superior de cada ação\n",
        "upper_bond = env.action_space.high\n",
        "print('Ligação superior de cada ação:', upper_bond[0])\n",
        "\n",
        "# vínculo inferior de cada ação\n",
        "lower_bond = env.action_space.low\n",
        "print('Ligação inferior de cada ação:', lower_bond[0])\n",
        "\n",
        "#examina o espaço de estados\n",
        "states = env.observation_space\n",
        "state_size = states.shape[0]\n",
        "print('Cada um observa um estado com comprimento: {}'.format(state_size))\n",
        "\n",
        "agent = TD3Agent(state_size=env.observation_space.shape[0], \\\n",
        "                 action_size=env.action_space.shape[0], \\\n",
        "                 max_action=env.action_space.high, \\\n",
        "                 min_action=env.action_space.low, random_seed=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "9f0c90394dc545e1a036d108e7cfa1fd",
            "1cb43ecead30414e8636a0e773d90bcf",
            "305769d2049547fc84c1a0fc4fd1f16b",
            "bfcb84944dbf46b687e2c58c1240b863",
            "e41ed5243e3044a6a22b0fb5195300a0",
            "ec916a290d164ed5aeb4926f49a28cf9",
            "f1d865e333164314a847884045d8e4bf",
            "a218779fe7fd4aefa6089871e981abe2"
          ]
        },
        "id": "RVNLbR1PNH44",
        "outputId": "8cb061e5-eb31-49c9-a5a5-577a28774f78"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:5ubs1zm7) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f0c90394dc545e1a036d108e7cfa1fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Q</td><td>▁▂▂▂▂▂▃▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▄▄▅▆▇███</td></tr><tr><td>Max. Q</td><td>▁▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▄▅▅▅▅▆▄▅▅▅▅▅▅▆██▇▆▆▆</td></tr><tr><td>loss</td><td>█▂▁▁▁▁▁▁▁▂▁▂▂▁▁▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▁▂▂</td></tr><tr><td>score</td><td>▄▁▂▃▃▅▅▅▄▃▃▄▃▃▂▂▃▄▅▄▄▄▄▅▅▆▆▇█▇▆▅▃▃▃▂▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Q</td><td>22.94519</td></tr><tr><td>Max. Q</td><td>37.44434</td></tr><tr><td>loss</td><td>2.22456</td></tr><tr><td>score</td><td>-115.57354</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ancient-terrain-26</strong> at: <a href='https://wandb.ai/grottimeireles/td3/runs/5ubs1zm7' target=\"_blank\">https://wandb.ai/grottimeireles/td3/runs/5ubs1zm7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231028_194004-5ubs1zm7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:5ubs1zm7). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231028_205732-0c206u52</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/grottimeireles/td3/runs/0c206u52' target=\"_blank\">effortless-lake-27</a></strong> to <a href='https://wandb.ai/grottimeireles/td3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/grottimeireles/td3' target=\"_blank\">https://wandb.ai/grottimeireles/td3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/grottimeireles/td3/runs/0c206u52' target=\"_blank\">https://wandb.ai/grottimeireles/td3/runs/0c206u52</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/grottimeireles/td3/runs/0c206u52?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f1c34086ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"td3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERQ6QREQC99V",
        "outputId": "f67ae506-9026-4e2a-c171-b1057a2c3e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100\tAverage Score: -104.91\n",
            "Episode 200\tAverage Score: -114.78\n",
            "Episode 300\tAverage Score: -112.16\n",
            "Episode 346\tAverage Score: -114.56\tScore: -132.29"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "def td3(n_episodes=1000, max_t=2000):\n",
        "    scores_deque = deque(maxlen=100)\n",
        "    scores = []\n",
        "    solved = False\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        state = env.reset()\n",
        "        score = 0\n",
        "        for t in range(max_t):\n",
        "            action = agent.predict(state)\n",
        "            next_state, reward, done, _, _ = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "            if done or t==(max_t-1):\n",
        "                loss, q, max = agent.learn(t)\n",
        "                break\n",
        "\n",
        "        scores_deque.append(score)\n",
        "        scores.append(score)\n",
        "        mean_score = np.mean(scores_deque)\n",
        "\n",
        "        wandb.log({'score': mean_score, 'loss': loss, 'Average Q': q, 'Max. Q': max}, step=i_episode)\n",
        "\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, mean_score, score), end=\"\")\n",
        "        if i_episode % 100 == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, mean_score))\n",
        "        if mean_score >= 300 and solved == False:\n",
        "            solved = True\n",
        "            print('\\rSolved at Episode {} !\\tAverage Score: {:.2f}'.format(i_episode, mean_score))\n",
        "\n",
        "            agent.save(\"checkpoint\")\n",
        "\n",
        "    return scores\n",
        "\n",
        "scores = td3()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Result**"
      ],
      "metadata": {
        "id": "_GJ4lM-g8jB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalações para ver o agente\n",
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet"
      ],
      "metadata": {
        "id": "p7xRX7rx8l1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "import gym\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "agent.actor_local.load_state_dict(torch.load('actor_checkpoint.pth'))\n",
        "agent.critic_local.load_state_dict(torch.load('critic_checkpoint.pth'))\n",
        "\n",
        "env = gym.make('BipedalWalker-v3')\n",
        "state = env.reset()\n",
        "score = 0\n",
        "img = plt.imshow(env.render('rgb_array'))\n",
        "while True:\n",
        "    img.set_data(env.render('rgb_array'))\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    action = agent.predict(state)\n",
        "    next_state, reward, done, _, _ = env.step(action)\n",
        "    state = next_state\n",
        "    score += reward\n",
        "    if np.any(done):\n",
        "        break\n",
        "\n",
        "print(\"Score: {}\".format(score))"
      ],
      "metadata": {
        "id": "IXJHQR6N8uwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Custom Env**"
      ],
      "metadata": {
        "id": "5xJXZ1fl8mCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame\n",
        "import math\n",
        "\n",
        "screen_width = 1500\n",
        "screen_height = 800\n",
        "check_point = ((1200, 660), (1250, 120), (190, 200), (1030, 270), (250, 475), (650, 690))\n",
        "\n",
        "class Car:\n",
        "    def __init__(self, car_file, map_file, pos):\n",
        "        self.surface = pygame.image.load(car_file)\n",
        "        self.map = pygame.image.load(map_file)\n",
        "        self.surface = pygame.transform.scale(self.surface, (100, 100))\n",
        "        self.rotate_surface = self.surface\n",
        "        self.pos = pos\n",
        "        self.angle = 0\n",
        "        self.speed = 0\n",
        "        self.center = [self.pos[0] + 50, self.pos[1] + 50]\n",
        "        self.radars = []\n",
        "        self.radars_for_draw = []\n",
        "        self.is_alive = True\n",
        "        self.current_check = 0\n",
        "        self.prev_distance = 0\n",
        "        self.cur_distance = 0\n",
        "        self.goal = False\n",
        "        self.check_flag = False\n",
        "        self.distance = 0\n",
        "        self.time_spent = 0\n",
        "        for d in range(-90, 120, 45):\n",
        "            self.check_radar(d)\n",
        "\n",
        "        for d in range(-90, 120, 45):\n",
        "            self.check_radar_for_draw(d)\n",
        "\n",
        "    def draw(self, screen):\n",
        "        screen.blit(self.rotate_surface, self.pos)\n",
        "\n",
        "    def draw_collision(self, screen):\n",
        "        for i in range(4):\n",
        "            x = int(self.four_points[i][0])\n",
        "            y = int(self.four_points[i][1])\n",
        "            pygame.draw.circle(screen, (255, 255, 255), (x, y), 5)\n",
        "\n",
        "    def draw_radar(self, screen):\n",
        "        for r in self.radars_for_draw:\n",
        "            pos, dist = r\n",
        "            pygame.draw.line(screen, (0, 255, 0), self.center, pos, 1)\n",
        "            pygame.draw.circle(screen, (0, 255, 0), pos, 5)\n",
        "\n",
        "    def check_collision(self):\n",
        "        self.is_alive = True\n",
        "        for p in self.four_points:\n",
        "            if self.map.get_at((int(p[0]), int(p[1]))) == (255, 255, 255, 255):\n",
        "                self.is_alive = False\n",
        "                break\n",
        "\n",
        "    def check_radar(self, degree):\n",
        "        len = 0\n",
        "        x = int(self.center[0] + math.cos(math.radians(360 - (self.angle + degree))) * len)\n",
        "        y = int(self.center[1] + math.sin(math.radians(360 - (self.angle + degree))) * len)\n",
        "\n",
        "        while not self.map.get_at((x, y)) == (255, 255, 255, 255) and len < 300:\n",
        "            len = len + 1\n",
        "            x = int(self.center[0] + math.cos(math.radians(360 - (self.angle + degree))) * len)\n",
        "            y = int(self.center[1] + math.sin(math.radians(360 - (self.angle + degree))) * len)\n",
        "\n",
        "        dist = int(math.sqrt(math.pow(x - self.center[0], 2) + math.pow(y - self.center[1], 2)))\n",
        "        self.radars.append([(x, y), dist])\n",
        "\n",
        "\n",
        "    def check_radar_for_draw(self, degree):\n",
        "        len = 0\n",
        "        x = int(self.center[0] + math.cos(math.radians(360 - (self.angle + degree))) * len)\n",
        "        y = int(self.center[1] + math.sin(math.radians(360 - (self.angle + degree))) * len)\n",
        "\n",
        "        while not self.map.get_at((x, y)) == (255, 255, 255, 255) and len < 300:\n",
        "            len = len + 1\n",
        "            x = int(self.center[0] + math.cos(math.radians(360 - (self.angle + degree))) * len)\n",
        "            y = int(self.center[1] + math.sin(math.radians(360 - (self.angle + degree))) * len)\n",
        "\n",
        "        dist = int(math.sqrt(math.pow(x - self.center[0], 2) + math.pow(y - self.center[1], 2)))\n",
        "        self.radars_for_draw.append([(x, y), dist])\n",
        "\n",
        "    def check_checkpoint(self):\n",
        "        p = check_point[self.current_check]\n",
        "        self.prev_distance = self.cur_distance\n",
        "        dist = get_distance(p, self.center)\n",
        "        if dist < 70:\n",
        "            self.current_check += 1\n",
        "            self.prev_distance = 9999\n",
        "            self.check_flag = True\n",
        "            if self.current_check >= len(check_point):\n",
        "                self.current_check = 0\n",
        "                self.goal = True\n",
        "            else:\n",
        "                self.goal = False\n",
        "\n",
        "        self.cur_distance = dist\n",
        "\n",
        "    def update(self):\n",
        "        #check speed\n",
        "        self.speed -= 0.5\n",
        "        if self.speed > 10:\n",
        "            self.speed = 10\n",
        "        if self.speed < 1:\n",
        "            self.speed = 1\n",
        "\n",
        "        #check position\n",
        "        self.rotate_surface = rot_center(self.surface, self.angle)\n",
        "        self.pos[0] += math.cos(math.radians(360 - self.angle)) * self.speed\n",
        "        if self.pos[0] < 20:\n",
        "            self.pos[0] = 20\n",
        "        elif self.pos[0] > screen_width - 120:\n",
        "            self.pos[0] = screen_width - 120\n",
        "\n",
        "        self.distance += self.speed\n",
        "        self.time_spent += 1\n",
        "        self.pos[1] += math.sin(math.radians(360 - self.angle)) * self.speed\n",
        "        if self.pos[1] < 20:\n",
        "            self.pos[1] = 20\n",
        "        elif self.pos[1] > screen_height - 120:\n",
        "            self.pos[1] = screen_height - 120\n",
        "\n",
        "        # caculate 4 collision points\n",
        "        self.center = [int(self.pos[0]) + 50, int(self.pos[1]) + 50]\n",
        "        len = 40\n",
        "        left_top = [self.center[0] + math.cos(math.radians(360 - (self.angle + 30))) * len, self.center[1] + math.sin(math.radians(360 - (self.angle + 30))) * len]\n",
        "        right_top = [self.center[0] + math.cos(math.radians(360 - (self.angle + 150))) * len, self.center[1] + math.sin(math.radians(360 - (self.angle + 150))) * len]\n",
        "        left_bottom = [self.center[0] + math.cos(math.radians(360 - (self.angle + 210))) * len, self.center[1] + math.sin(math.radians(360 - (self.angle + 210))) * len]\n",
        "        right_bottom = [self.center[0] + math.cos(math.radians(360 - (self.angle + 330))) * len, self.center[1] + math.sin(math.radians(360 - (self.angle + 330))) * len]\n",
        "        self.four_points = [left_top, right_top, left_bottom, right_bottom]\n",
        "\n",
        "class PyGame2D:\n",
        "    def __init__(self):\n",
        "        pygame.init()\n",
        "        self.screen = pygame.display.set_mode((screen_width, screen_height))\n",
        "        self.clock = pygame.time.Clock()\n",
        "        self.font = pygame.font.SysFont(\"Arial\", 30)\n",
        "        self.car = Car('car.png', 'map.png', [700, 650])\n",
        "        self.game_speed = 60\n",
        "        self.mode = 0\n",
        "\n",
        "    def action(self, action):\n",
        "        if action == 0:\n",
        "            self.car.speed += 2\n",
        "        if action == 1:\n",
        "            self.car.angle += 5\n",
        "        elif action == 2:\n",
        "            self.car.angle -= 5\n",
        "\n",
        "        self.car.update()\n",
        "        self.car.check_collision()\n",
        "        self.car.check_checkpoint()\n",
        "\n",
        "        self.car.radars.clear()\n",
        "        for d in range(-90, 120, 45):\n",
        "            self.car.check_radar(d)\n",
        "\n",
        "    def evaluate(self):\n",
        "        reward = 0\n",
        "        \"\"\"\n",
        "        if self.car.check_flag:\n",
        "            self.car.check_flag = False\n",
        "            reward = 2000 - self.car.time_spent\n",
        "            self.car.time_spent = 0\n",
        "        \"\"\"\n",
        "        if not self.car.is_alive:\n",
        "            reward = -10000 + self.car.distance\n",
        "\n",
        "        elif self.car.goal:\n",
        "            reward = 10000\n",
        "        return reward\n",
        "\n",
        "    def is_done(self):\n",
        "        if not self.car.is_alive or self.car.goal:\n",
        "            self.car.current_check = 0\n",
        "            self.car.distance = 0\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def observe(self):\n",
        "        # return state\n",
        "        radars = self.car.radars\n",
        "        ret = [0, 0, 0, 0, 0]\n",
        "        for i, r in enumerate(radars):\n",
        "            ret[i] = int(r[1] / 30)\n",
        "\n",
        "        return tuple(ret)\n",
        "\n",
        "    def view(self):\n",
        "        # draw game\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:\n",
        "                done = True\n",
        "            elif event.type == pygame.KEYDOWN:\n",
        "                if event.key == pygame.K_m:\n",
        "                    self.mode += 1\n",
        "                    self.mode = self.mode % 3\n",
        "\n",
        "        self.screen.blit(self.car.map, (0, 0))\n",
        "\n",
        "\n",
        "        if self.mode == 1:\n",
        "            self.screen.fill((0, 0, 0))\n",
        "\n",
        "        self.car.radars_for_draw.clear()\n",
        "        for d in range(-90, 120, 45):\n",
        "            self.car.check_radar_for_draw(d)\n",
        "\n",
        "        pygame.draw.circle(self.screen, (255, 255, 0), check_point[self.car.current_check], 70, 1)\n",
        "        self.car.draw_collision(self.screen)\n",
        "        self.car.draw_radar(self.screen)\n",
        "        self.car.draw(self.screen)\n",
        "\n",
        "\n",
        "        text = self.font.render(\"Press 'm' to change view mode\", True, (255, 255, 0))\n",
        "        text_rect = text.get_rect()\n",
        "        text_rect.center = (screen_width/2, 100)\n",
        "        self.screen.blit(text, text_rect)\n",
        "\n",
        "\n",
        "\n",
        "        pygame.display.flip()\n",
        "        self.clock.tick(self.game_speed)\n",
        "\n",
        "\n",
        "def get_distance(p1, p2):\n",
        "\treturn math.sqrt(math.pow((p1[0] - p2[0]), 2) + math.pow((p1[1] - p2[1]), 2))\n",
        "\n",
        "def rot_center(image, angle):\n",
        "    orig_rect = image.get_rect()\n",
        "    rot_image = pygame.transform.rotate(image, angle)\n",
        "    rot_rect = orig_rect.copy()\n",
        "    rot_rect.center = rot_image.get_rect().center\n",
        "    rot_image = rot_image.subsurface(rot_rect).copy()\n",
        "    return rot_image\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "class CustomEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        self.pygame = PyGame2D()\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        self.observation_space = spaces.Box(np.array([0, 0, 0, 0, 0]), np.array([10, 10, 10, 10, 10]), dtype=np.int)\n",
        "\n",
        "    def reset(self):\n",
        "        del self.pygame\n",
        "        self.pygame = PyGame2D()\n",
        "        obs = self.pygame.observe()\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        self.pygame.action(action)\n",
        "        obs = self.pygame.observe()\n",
        "        reward = self.pygame.evaluate()\n",
        "        done = self.pygame.is_done()\n",
        "        return obs, reward, done, {}\n",
        "\n",
        "    def render(self, mode=\"human\", close=False):\n",
        "        self.pygame.view()"
      ],
      "metadata": {
        "id": "B_HMmQ2k8m-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qUkL1MTSs3Nn",
        "gkNza9le_wuU",
        "_GJ4lM-g8jB9",
        "5xJXZ1fl8mCL"
      ],
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMZj/zUpt0qfYO2J3ksxW09",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f0c90394dc545e1a036d108e7cfa1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cb43ecead30414e8636a0e773d90bcf",
              "IPY_MODEL_305769d2049547fc84c1a0fc4fd1f16b"
            ],
            "layout": "IPY_MODEL_bfcb84944dbf46b687e2c58c1240b863"
          }
        },
        "1cb43ecead30414e8636a0e773d90bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e41ed5243e3044a6a22b0fb5195300a0",
            "placeholder": "​",
            "style": "IPY_MODEL_ec916a290d164ed5aeb4926f49a28cf9",
            "value": "0.002 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "305769d2049547fc84c1a0fc4fd1f16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1d865e333164314a847884045d8e4bf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a218779fe7fd4aefa6089871e981abe2",
            "value": 0.20824915824915824
          }
        },
        "bfcb84944dbf46b687e2c58c1240b863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41ed5243e3044a6a22b0fb5195300a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec916a290d164ed5aeb4926f49a28cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1d865e333164314a847884045d8e4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a218779fe7fd4aefa6089871e981abe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}